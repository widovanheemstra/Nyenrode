{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering with spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.mllib.evaluation import RankingMetrics, RegressionMetrics\n",
    "from pyspark.mllib.recommendation import ALS, Rating\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Spark**\n",
    "- Transformations vs Actions\n",
    "- Distributed\n",
    "- Huge datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Loading data: movielens data\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = spark.read.csv(\"../data/movielens/ratings.csv\", header=True).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. EDA\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total amount of ratings: {}\".format(ratings.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Amount of unique users: {}\".format(ratings.select('userId').distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Amount of unique movies: {}\".format(ratings.select('movieId').distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sparsity: {:0.5f}\".format(ratings.count() /\n",
    "                                 (ratings.select('userId').distinct().count() *\n",
    "                                  ratings.select('movieId').distinct().count())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to a datetime value\n",
    "ratings = ratings.withColumn('ts', F.from_unixtime('timestamp'))\n",
    "ratings.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ts = datetime.strptime(ratings.agg({\"ts\":\"max\"}).collect()[0][0],'%Y-%m-%d %H:%M:%S')\n",
    "min_ts = datetime.strptime(ratings.agg({\"ts\":\"min\"}).collect()[0][0],'%Y-%m-%d %H:%M:%S')\n",
    "print(\"Min datum: {}\\nMax datum {}\\nVerschil in jaren: {:0.1f}\".format(min_ts, max_ts, (max_ts - min_ts).days / 365))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Movie perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 20 of most rated movies\n",
    "rating_cnt = ratings.groupby('movieId').count()\n",
    "rating_cnt.orderBy('count', ascending=False).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the counts per movie\n",
    "rating_cnt.orderBy('count', ascending=False).toPandas().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts per rating for each movie\n",
    "rating_cnt_2 = ratings.groupby('movieId').pivot('rating').agg({\"rating\":\"count\"}).na.fill(0)\n",
    "rating_cnt_2.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total rating count per category\n",
    "\n",
    "agg_functions = [\n",
    "    F.sum(F.col('`0.5`')).alias('0.5'),\n",
    "    F.sum('`1.0`').alias('1.0'),\n",
    "    F.sum('`1.5`').alias('1.5'),\n",
    "    F.sum('`2.0`').alias('2.0'),\n",
    "    F.sum('`2.5`').alias('2.5'),\n",
    "    F.sum('`3.0`').alias('3.0'),\n",
    "    F.sum('`3.5`').alias('3.5'),\n",
    "    F.sum('`4.0`').alias('4.0'),\n",
    "    F.sum('`4.5`').alias('4.5'),\n",
    "    F.sum('`5.0`').alias('5.0')\n",
    "]\n",
    "\n",
    "agg_ratings = rating_cnt_2.agg(*agg_functions)\n",
    "agg_ratings.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_ratings.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas is required to get nice graphs\n",
    "agg_ratings.toPandas().T.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 User perspective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count amount of ratings given per user\n",
    "user_rating_cnt = ratings.groupby('userId').count()\n",
    "user_rating_cnt.orderBy('count', ascending=False).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order and plot\n",
    "user_rating_cnt.orderBy('count', ascending=False).toPandas().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data prep\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm that we will choose determines how the input data must look like. Having the model or models clear is important in order to prepare the data.\n",
    "\n",
    "We choose to use the Alternating Least Squares (ALS), which comes out of the box with spark. This is a Matrix Factorization (MF) algorithm and belongs to the Model Based Collaborative Filtering recommenders.\n",
    "\n",
    "### Matrix Factorization\n",
    "Matrix Factorization is mostly used for dimensionality reduction e.g. Principle Component Analysis (PCA) or Singular Value Decomposition (SVD). In principle MF tries to find the hidden features that relate, in this case, the users and items in a smaller matrix.\n",
    "\n",
    "The image below shows  the original rating matrix R, user-feature matrix U and the feature-item matrix V. \n",
    "\n",
    "![Matrix Factorization](images/mf2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model intuition\n",
    "\n",
    "The ALS model is iterative by nature. In order to find the right U and V, these matrices are randomly initiated and then by using least squares the model optimizes U while fixing V and vice versa. Each time we optimise we get closer to the real rating matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data structure\n",
    "The ALS model requires the users and items represented as integers (identifiers). The rating column is of type float (decimal numbers) The date column is not necessary.\n",
    "\n",
    "We can change the ratings given into relevance scores. How this is done is highly subjective. We choose not to recommend ratings lower than 3. So we need to map the ratings to a new relevance score.\n",
    "- 5 -> 2.5\n",
    "- 4 -> 1.5\n",
    "- 3 -> 0.5\n",
    "- 2 -> -0.5\n",
    "- 1 -> -1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new rating set with relevance scores.\n",
    "rating_prep = ratings.rdd.map(lambda r: Rating(int(r[0]), int(r[1]), float(r[2])-2.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_prep.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the recommendation model using the user-product relevance scores\n",
    "\n",
    "# parameters\n",
    "latent_factors = 10\n",
    "iterations = 10\n",
    "regularization = 0.01\n",
    "seed = 123\n",
    "\n",
    "model_1 = ALS.train(rating_prep,\n",
    "                  rank=latent_factors,\n",
    "                  iterations=iterations,\n",
    "                  lambda_=regularization,\n",
    "                  seed=seed\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = rating_prep.map(lambda p: (p.user, p.product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all user-movie combination\n",
    "predictions = model_1.predictAll(testData).map(lambda r: ((r.user, r.product), r.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTuple = rating_prep.map(lambda r: ((r.user, r.product), r.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTuple.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreAndLabels = predictions.join(ratingsTuple).map(lambda tup: tup[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = RegressionMetrics(scoreAndLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R-squared = %s\" % metrics.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the right parameters: grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "latent_factors = [5, 10, 20]\n",
    "iterations = [5, 10, 15]\n",
    "regularization = [0.005, 0.01, 0.05]\n",
    "seed = 123\n",
    "\n",
    "r2_best = 0\n",
    "lf_best = 0\n",
    "it_best = 0\n",
    "rg_best = 0\n",
    "\n",
    "\n",
    "testData = rating_prep.map(lambda p: (p.user, p.product))\n",
    "ratingsTuple = rating_prep.map(lambda r: ((r.user, r.product), r.rating))\n",
    "\n",
    "for (lf, it, rg) in itertools.product(latent_factors, iterations, regularization):\n",
    "    model = ALS.train(rating_prep,\n",
    "                  rank=lf,\n",
    "                  iterations=it,\n",
    "                  lambda_=rg,\n",
    "                  seed=seed\n",
    "                 )\n",
    "    pred = model.predictAll(testData).map(lambda r: ((r.user, r.product), r.rating))\n",
    "    scoreAndLabels = pred.join(ratingsTuple).map(lambda tup: tup[1])\n",
    "    metrics = RegressionMetrics(scoreAndLabels)\n",
    "    r2 = metrics.r2\n",
    "    print(\"Lf: {}, Iter: {}, Reg: {}, R-squared: {}\".format(lf, it, rg, metrics.r2))\n",
    "    if r2 > r2_best:\n",
    "        r2_best = r2\n",
    "        lf_best = lf\n",
    "        it_best = it\n",
    "        rg_best = rg\n",
    "        \n",
    "\n",
    "print(\"Best parameters:\\n\\tLatent Factors: {}\\n\\tIterations: {}\\n\\tLearning rate: {}\\n\\tR-squared: {}\".format(lf_best, it_best, rg_best, r2_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2\n",
    "# parameters\n",
    "latent_factors = [5, 10, 20, 30, 40, 50]\n",
    "iterations = 15\n",
    "regularization = 0.005\n",
    "seed = 123\n",
    "\n",
    "r2_best = 0\n",
    "lf_best = 0\n",
    "\n",
    "\n",
    "testData = rating_prep.map(lambda p: (p.user, p.product))\n",
    "ratingsTuple = rating_prep.map(lambda r: ((r.user, r.product), r.rating))\n",
    "\n",
    "for lf in latent_factors:\n",
    "    model = ALS.train(rating_prep,\n",
    "                  rank=lf,\n",
    "                  iterations=iterations,\n",
    "                  lambda_=regularization,\n",
    "                  seed=seed\n",
    "                 )\n",
    "    pred = model.predictAll(testData).map(lambda r: ((r.user, r.product), r.rating))\n",
    "    scoreAndLabels = pred.join(ratingsTuple).map(lambda tup: tup[1])\n",
    "    metrics = RegressionMetrics(scoreAndLabels)\n",
    "    r2 = metrics.r2\n",
    "    print(\"Lf: {}, R-squared: {}\".format(lf, metrics.r2))\n",
    "    if r2 > r2_best:\n",
    "        r2_best = r2\n",
    "        lf_best = lf\n",
    "\n",
    "        \n",
    "\n",
    "print(\"Best parameters:\\n\\tLatent Factors: {}\\n\\tR-squared: {}\".format(lf_best, r2_best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model\n",
    "model_final = ALS.train(rating_prep,\n",
    "                  rank=lf_best,\n",
    "                  iterations=15,\n",
    "                  lambda_=0.005,\n",
    "                  seed=seed\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top N predictions for a user\n",
    "\n",
    "N = 10\n",
    "userId = 1\n",
    "\n",
    "model_1.recommendProducts(userId, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 movie recommendations for each user\n",
    "userRecs10 = model.recommendForAllUsers(10)\n",
    "# Generate top 10 user recommendations for each movie\n",
    "movieRecs10 = model.recommendForAllItems(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "- Data: https://grouplens.org/datasets/movielens/latest/\n",
    "- https://datasciencemadesimpler.wordpress.com/tag/alternating-least-squares/\n",
    "- https://medium.com/radon-dev/als-implicit-collaborative-filtering-5ed653ba39fe\n",
    "- https://spark.apache.org/docs/latest/ml-collaborative-filtering.html\n",
    "- https://jessesw.com/Rec-System/\n",
    "- https://www.blabladata.com/2014/12/20/simple-multimodal-design-recommender/\n",
    "- http://fastml.com/evaluating-recommender-systems/\n",
    "- http://yifanhu.net/PUB/cf.pdf\n",
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
