{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will demonstrate how to create a basic recommender system (RS) for books. The RS will take as input a historic set of book ratings from multiple reviewers. For a given book it then suggests what other books might be interesting. We find this in some online shops as well.\n",
    "\n",
    "In the accompanied presentation some types of Recommender Systems are explained including a manual calculation for User and Item Based Recommenders. Below we will develop a simple Item Based Recommender.\n",
    "\n",
    "This notebook is by no means complete. The purpose is to give a quick hands-on experience with building a data product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Item Based Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a start we import some python libraries that we require for our prototype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "#matplotlib.use('tkagg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Inspect and prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going the create a book recommender and for that we need books and user ratings. We will use a dataset from [Book-Crossing](http://www2.informatik.uni-freiburg.de/~cziegler/BX/) which is already transformed into usable user-book-rating format. So that forst step has been done. ;-)\n",
    "\n",
    "We also have to think about how we will evaluate the performance of our RS in the end and therefore how to prepare the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lets read-in the data and see how the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data_books.csv\", sep = \",\", header=None, names=['Reviewer', 'Book', 'Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's see how the dataframe looks like\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To get some feeling with the data, we want to get a few statistics:\n",
    "- Size of the dataset\n",
    "- Amount of unique books and unique reviewers\n",
    "- Top 20 most reviewed books and reviewers\n",
    "- The sparsity of the user-item matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the dimensions of the dataframe\n",
    "dim = data.shape\n",
    "print (\"There are {:d} rows/records in this dataframe and {:d} columns/features.\".format(dim[0], dim[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_books = pd.unique(data[['Book']].values.ravel()).size\n",
    "print (\"{:d} unique books.\".format(unique_books))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unique_reviewers = pd.unique(data[['Reviewer']].values.ravel()).size\n",
    "print (\"{:d} unique reviewers.\".format(unique_reviewers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top 20 most reviewed books \n",
    "top_books = pd.value_counts(data.Book)\n",
    "top_books.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Lets show a graph of the top 1000 most reviewed books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(top_books[:1000].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Top Reviewers\n",
    "top_reviewers = pd.value_counts(data.Reviewer)\n",
    "top_reviewers.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(top_reviewers[:100].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question**: Do we see something interesting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The sparsity is calculated as the fraction of non-empty cells over the total amount of cells in the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Total matrix would be\n",
    "total_cells = unique_reviewers * unique_books\n",
    "\n",
    "# How sparse is the matrix now\n",
    "perc = dim[0] / float(total_cells) * 100.\n",
    "print ('{:.4f}%'.format(perc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Discussion**: How can we evaluate the performance of a top-N recommender system?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Discussion**: How to prepare the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare the train and test datasets** and save them as files for later. For this exercise we only take the records of only those reviewers for which we have more than two reviews. The highest rated review will go into the test dataset and the other reviews will be added to the train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "```python\n",
    "# This is working code, but will take about 15 minutes to run\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "grouped = data.groupby(['Reviewer'])\n",
    "\n",
    "for k, g in grouped:\n",
    "    # We are only interested in reviewers with more than 2 reviews\n",
    "    if len(g) > 2:\n",
    "        print k\n",
    "        g.sort_values('Rating', ascending=False, inplace=True)\n",
    "        test = test.append(g.iloc[:1])\n",
    "        train = train.append(g.iloc[1:])\n",
    "        \n",
    "train.to_csv('train_books.csv', index=False)\n",
    "test.to_csv('test_books.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_books.csv\", sep = \",\")\n",
    "test = pd.read_csv(\"test_books.csv\", sep = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print ('Train: {:d}, Test: {:d}'.format(train.shape[0], test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Size and performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For performance reasons we will select the top most reviewed books for the calculation of similarity between all book pairs will take too much time. This is the reason why these calculations are executed seperately from the online scoring mechanism.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "most_reviewed_books = pd.DataFrame({'count' : train.groupby([\"Book\"]).size()})\\\n",
    "                                    .reset_index().sort_values(['count'],ascending = False)\n",
    "\n",
    "most_reviewed_books.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Why do we see less review for *The Lovely Bones: A Novel*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need these names in a list for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the list of the most reviewed books\n",
    "top_books = []\n",
    "\n",
    "for i in most_reviewed_books.Book[0:20]:\n",
    "    top_books.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lets use the wisdom of the Crowd! Calculating Similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For the top rated books we need to calculate their mutual similarities.\n",
    "In order to do so we will start simple by calculating the mutual similarity of two books and then generalize this for any two book. The similarity will be determined by Pearson-correlation.\n",
    "\n",
    "**Approach**:\n",
    "- Choose two books\n",
    "- Determine their shared reviewers\n",
    "- Get for each book a list of all reviews of their shared reviewers.\n",
    "- Calculate the Pearson-correlation over these reviews\n",
    "\n",
    "Cosine similarity:\n",
    "$$\\cos (\\theta) = \\frac{v \\cdot w }{\\left \\| v \\right \\|*\\left \\| w \\right \\|} = \\frac{\\sum_{i=1}^{n} v_{i} u_{i}}{\\sqrt{\\sum_{i=1}^{n} v_{i}^{2}} \\sqrt{\\sum_{i=1}^{n} u_{i}^{2}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose two book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "book_1, book_2 = \"Harry Potter and the Chamber of Secrets\", \"Harry Potter and the Sorcerer's Stone (Harry Potter)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the shared reviewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Getting all the reviewers for these books. For this we still need the train dataset as source.\n",
    "book_1_reviewers = train[train.Book == book_1].Reviewer\n",
    "book_2_reviewers = train[train.Book == book_2].Reviewer\n",
    "\n",
    "# Determine any common reviewers\n",
    "common_reviewers = set(book_1_reviewers).intersection(book_2_reviewers)\n",
    "\n",
    "print \"%d people have reviewed both books\" % len(common_reviewers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the ratings for both books given by the shared reviewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Checking the table with only the common reviewers and get the book name and rating\n",
    "com_rev_book1 = train[(train.Reviewer.isin(common_reviewers)) & (train.Book == book_1)]\n",
    "com_rev_book2 = train[(train.Reviewer.isin(common_reviewers)) & (train.Book == book_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "com_rev_book1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "com_rev_book2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see duplicate reviewers, that must be fixed to calculate the Pearson-correlation as we need two vectors of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fix the duplicates to prevent errors when calculating Pearson-correlation.\n",
    "com_rev_book1.sort_values('Reviewer')\n",
    "com_rev_book1 = com_rev_book1[com_rev_book1.Reviewer.duplicated()==False]\n",
    "\n",
    "com_rev_book1.sort_values('Reviewer')\n",
    "com_rev_book1 = com_rev_book1[com_rev_book1.Reviewer.duplicated()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosin_sim(v, w):\n",
    "    return np.dot(v, w) / np.math.sqrt(np.dot(v, v) * np.dot(w, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cosin_sim(com_rev_book1.Rating, com_rev_book2.Rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two books that look quit correlated or similar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create reusable code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the similarity for any two books we need to build two functions that will make our live much more easy.\n",
    "\n",
    "1. A function that helps us to retrieve the reviews for a specific book given a shared set of reviewers with another book\n",
    "2. A function that helps us calculating the Cosine similarity for two books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First let's create a function that collects the reviews of our common reviewers for a specified book\n",
    "def get_book_reviews(title, common_reviewers):\n",
    "    mask = (train.Reviewer.isin(common_reviewers)) & (train.Book==title)\n",
    "    reviews = train[mask].sort_values('Reviewer')\n",
    "    reviews = reviews[reviews.Reviewer.duplicated()==False]\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that we get the same correlation as had before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(book1, book2):\n",
    "    # We start by finding the common reviewers\n",
    "    book_1_reviewers = train[train.Book == book1].Reviewer\n",
    "    book_2_reviewers = train[train.Book == book2].Reviewer\n",
    "    common_reviewers = set(book_1_reviewers).intersection(book_2_reviewers)\n",
    "\n",
    "    # Then we look for the reviews given by common reviewers\n",
    "    book_1_reviews = get_book_reviews(book1, common_reviewers)\n",
    "    book_2_reviews = get_book_reviews(book2, common_reviewers)\n",
    "    \n",
    "    # Calculate the Pearson Correlation Score\n",
    "    return cosin_sim(book_1_reviews.Rating, book_2_reviews.Rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Print the correlation score\n",
    "calculate_cosine_similarity(book_1,book_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating these similarities in real-time and for many users in parallel will require huge computation power. But this type of Recommender System (Item Based) has the advantage to have the mutual book similarities be pre calculated.\n",
    "\n",
    "Lets do that!\n",
    "\n",
    "Build the matrix with all mutual similaroties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the correlation for our top books\n",
    "correlation_coefficient = []\n",
    "\n",
    "for book1 in top_books:\n",
    "    print \"Calculating the correlations for:\", book1\n",
    "    for book2 in top_books:\n",
    "        if book1 != book2:\n",
    "            row = [book1, book2] + [calculate_cosine_similarity(book1, book2)]\n",
    "            correlation_coefficient.append(row)\n",
    "            \n",
    "print \"Done calculating.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dictionary is converted back into a pandas DataFrame to make it more easy to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the columns to use\n",
    "cols = [\"Book_1\", \"Book_2\", \"Correlation\"]\n",
    "correlation_coefficient = pd.DataFrame(correlation_coefficient, columns=cols).sort_values('Correlation')\n",
    "#correlation_coefficient.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what is the size of correlation matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correlation_coefficient.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the Recommender System\n",
    "\n",
    "So now we need a function that gives us a similarity score for two any books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# corr is the pre calculated similarity matrix\n",
    "def calc_correlation(corr, book1, book2):\n",
    "    mask = (corr.Book_1==book1) & (corr.Book_2==book2)\n",
    "    row = corr[mask]\n",
    "    corr = row\n",
    "    return corr.sum(axis=1).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "calc_correlation(correlation_coefficient,\"Harry Potter and the Chamber of Secrets\", \"Harry Potter and the Sorcerer's Stone (Harry Potter)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check: for \"Harry Potter and the Chamber of Secrets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the sorted correlations for Harry Potter\n",
    "my_book = \"Harry Potter and the Chamber of Secrets\"\n",
    "\n",
    "results = []\n",
    "for b in top_books:\n",
    "    if my_book!=b:\n",
    "        results.append((b, calc_correlation(correlation_coefficient, my_book, b)))\n",
    "sorted(results, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if we need a top-N instead of all?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_recommendations(my_book, topn=5):\n",
    "    results = []\n",
    "    for other_book in top_books:\n",
    "        if my_book != other_book:\n",
    "            correlation = calc_correlation(correlation_coefficient, my_book, other_book)\n",
    "            results.append((my_book, other_book, correlation))\n",
    "    if topn > len(results):\n",
    "        topn = len(results)\n",
    "    return pd.DataFrame.from_dict(sorted(results, key=lambda x: x[2], reverse=True))[:topn] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test for any given book, what suggestions we should consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_recommendations(\"Harry Potter and the Chamber of Secrets\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussion**: How would you apply this in your company or job?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Part of the code is from: http://www.mickaellegal.com/blog/2014/1/30/how-to-build-a-recommender\n",
    "- CF technique backgrounds are explained at http://www.hindawi.com/journals/aai/2009/421425/\n",
    "- Item-Based Top-N Recommendation Algorithms (Deshpande and Karypis)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
